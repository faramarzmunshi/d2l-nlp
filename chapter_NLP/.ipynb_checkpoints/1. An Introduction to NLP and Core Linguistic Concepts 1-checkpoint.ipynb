{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Let's first start by setting up our environment so we can use the textual corpora from Project Gutenberg! Because Python 3 removed the berkeley-db4 package from native Python, we have to reinstall it using homebrew. This also applies to the gzip package that made unzipping large files using python easier. If you don't have homebrew or you are not using a Mac, you can use \"apt-get\" on Linux OS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Homebrew...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 1 tap (homebrew/core).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "kubebuilder     now-cli         octant          pdftk-java      pokerstove\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "ack                        httping                    pjproject\n",
      "activemq-cpp               httrack                    pkcs11-helper\n",
      "afflib                     hyperfine                  plantuml\n",
      "afl-fuzz                   i2p                        platformio\n",
      "aircrack-ng                i2pd                       poco\n",
      "aliyun-cli                 icecast                    podofo\n",
      "alpine                     ike-scan                   ponyc\n",
      "amap                       imapfilter                 poppler\n",
      "amqp-cpp                   intercal                   pre-commit\n",
      "angular-cli                iperf3                     protobuf\n",
      "ansible                    ipython                    protobuf@3.6\n",
      "ansible@1.9                ircd-hybrid                protobuf@3.7\n",
      "ansible@2.0                ircii                      pulledpork\n",
      "apache-spark               irssi                      pure-ftpd\n",
      "apib                       jenkins                    pwntools\n",
      "appscale-tools             jenkins-lts                pwsafe\n",
      "arangodb                   jfrog-cli-go               pyenv\n",
      "aravis                     joplin                     pygobject3\n",
      "asio                       jose                       pyqt\n",
      "astrometry-net             juise                      pyside\n",
      "avfs                       juju                       python@2\n",
      "awscli                     kafka                      pyvim\n",
      "axel                       kore                       qca\n",
      "azure-cli                  krb5                       qmmp\n",
      "azure-storage-cpp          kubecfg                    qpdf\n",
      "bacula-fd                  kubectx                    qpid-proton\n",
      "bareos-client              kubeseal                   qscintilla2\n",
      "bash                       lazydocker                 qsoas\n",
      "bat                        ldapvi                     rabbitmq-c\n",
      "bazel                      ldid                       rclone\n",
      "bbftp-client               ldns                       rdesktop\n",
      "bcftools                   lftp                       re2\n",
      "benthos                    libbitcoin                 rename\n",
      "bibtexconv                 libbitcoin-blockchain      repo\n",
      "bigloo                     libbitcoin-client          riff\n",
      "blueutil                   libbitcoin-consensus       rmlint\n",
      "botan                      libbitcoin-database        rom-tools\n",
      "bro                        libbitcoin-explorer        root\n",
      "btfs                       libbitcoin-network         rtags\n",
      "btpd                       libbitcoin-node            ruby\n",
      "burp                       libbitcoin-protocol        ruby-build\n",
      "cabal-install              libbitcoin-server          ruby@2.4\n",
      "cadaver                    libdap                     ruby@2.5\n",
      "caf                        libdvbpsi                  s-nail\n",
      "cfn-lint                   libexosip                  s2geometry\n",
      "cgrep                      libfaketime                s3-backer\n",
      "charm-tools                libfreefare                sagittarius-scheme\n",
      "checkstyle                 libgcrypt                  sane-backends\n",
      "chronograf                 libheif                    sblim-sfcc\n",
      "clamav                     libjwt                     scamper\n",
      "clingo                     libmowgli                  scdoc\n",
      "collectd                   libphonenumber             scrypt\n",
      "conan                      libpulsar                  sdhash\n",
      "convox                     libre                      sdl2\n",
      "cpprestsdk                 librsvg                    serverless\n",
      "csound                     libsignal-protocol-c       shairport\n",
      "cubelib                    libslax                    shairport-sync\n",
      "davix                      libtins                    ship\n",
      "dcmtk                      libtrace                   siege\n",
      "dcos-cli                   libu2f-server              sile\n",
      "ddgr                       links                      sip\n",
      "dhall-bash                 logrotate                  sipsak\n",
      "dieharder                  logtalk                    siril\n",
      "diff-pdf                   lolcat                     skaffold\n",
      "diffoscope                 luvit                      skopeo\n",
      "django-completion          lynx                       slrn\n",
      "dnsviz                     mackup                     smali\n",
      "docfx                      makensis                   sn0int\n",
      "doctl                      makepkg                    sngrep\n",
      "dovecot                    md5sha1sum                 socat\n",
      "duo_unix                   memcached                  sofia-sip\n",
      "duplicity                  mfterm                     softhsm\n",
      "dylibbundler               minio                      sonobuoy\n",
      "dynare                     minio-mc                   sourcery\n",
      "efl                        miniserve                  sphinx\n",
      "ejabberd                   mit-scheme                 spiped\n",
      "ekg2                       mktorrent                  sqlcipher\n",
      "emacs                      mmark                      sqlmap\n",
      "embree                     molecule                   srt\n",
      "encfs                      monetdb                    ssh-audit\n",
      "epic5                      mongoose                   ssldump\n",
      "erlang@20                  monit                      step\n",
      "erlang@21                  monitoring-plugins         storm\n",
      "eslint                     mono                       stress-ng\n",
      "ethereum                   mpg123                     strongswan\n",
      "exim                       mupdf                      stunnel\n",
      "exploitdb                  mysql                      stuntman\n",
      "fauna-shell                mysql@5.7                  subnetcalc\n",
      "fdroidserver               nagios-plugins             swiftlint\n",
      "ffsend                     nano                       sylpheed\n",
      "fibjs                      nco                        sync_gateway\n",
      "findutils                  ncrack                     syncthing\n",
      "firebase-cli               neofetch                   sysdig\n",
      "flow                       neon                       tarantool\n",
      "flowgrind                  net-snmp                   taskell\n",
      "fluxctl                    netlify-cli                tcl-tk\n",
      "fn                         nginx                      tcpdump\n",
      "folly                      ngircd                     tcpflow\n",
      "fossil                     nmap                       tdlib\n",
      "fpp                        nmh                        telegraf\n",
      "fq                         node                       tinc\n",
      "freeradius-server          nomad                      tiny-fugue\n",
      "frugal                     nopoll                     tomcat-native\n",
      "gambit-scheme              nordugrid-arc              trafficserver\n",
      "gammu                      nrpe                       triton\n",
      "gdal                       nsq                        ttyd\n",
      "geoipupdate                nss                        tunnel\n",
      "gerbil-scheme              ntp                        typescript\n",
      "getdns                     nushell                    u-boot-tools\n",
      "getxbook                   nzbget                     unbound\n",
      "git-crypt                  ocrmypdf                   unrar\n",
      "gkrellm                    ooniprobe                  unshield\n",
      "glances                    opa                        uptimed\n",
      "glib                       opencolorio                uwsgi\n",
      "glib-openssl               opencv                     varnish\n",
      "globus-toolkit             opencv@3                   vault-cli\n",
      "glooctl                    openfortivpn               verilator\n",
      "gloox                      openimageio                vgmstream\n",
      "gnupg-pkcs11-scd           openrct2                   vim\n",
      "gnuradio                   opensc                     vips\n",
      "gocryptfs                  openssh                    visp\n",
      "goreleaser                 openvpn                    vtk\n",
      "gradle                     operator-sdk               wdc\n",
      "grafana                    ophcrack                   weechat\n",
      "groonga                    osc                        wskdeploy\n",
      "gsl                        oscats                     wtf\n",
      "gsoap                      osquery                    wtfutil\n",
      "gst-plugins-good           parallel                   xcodegen\n",
      "gtmess                     passenger                  xmake\n",
      "gwyddion                   pdftoipe                   youtube-dl\n",
      "h2o                        pdns                       zabbix\n",
      "haproxy                    pdnsrec                    zbackup\n",
      "hbase                      pev                        zim\n",
      "heimdal                    pgroonga                   znc\n",
      "hive                       php                        zsxd\n",
      "htpdate                    php@7.1\n",
      "http_load                  php@7.2\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDeleted Formulae\u001b[0m\n",
      "cherokee                   libopkele                  pincaster\n",
      "csup                       mongodb                    thc-pptp-bruter\n",
      "ctunnel                    mongodb@3.0                tlsdate\n",
      "frag_find                  mongodb@3.2                tn5250\n",
      "freetds@0.91               mongodb@3.4                xar-mackyle\n",
      "ftimes                     mongodb@3.6\n",
      "liblacewing                percona-server-mongodb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[33mWarning:\u001b[0m berkeley-db@4 4.8.30 is already installed and up-to-date\n",
      "To reinstall 4.8.30, run `brew reinstall berkeley-db@4`\n",
      "\u001b[33mWarning:\u001b[0m zlib 1.2.11 is already installed and up-to-date\n",
      "To reinstall 1.2.11, run `brew reinstall zlib`\n",
      "Requirement already satisfied: gutenberg in /usr/local/lib/python3.7/site-packages (0.8.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/site-packages (from gutenberg) (41.0.1)\n",
      "Requirement already satisfied: bsddb3>=6.1.0 in /usr/local/lib/python3.7/site-packages (from gutenberg) (6.2.6)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from gutenberg) (1.12.0)\n",
      "Requirement already satisfied: requests>=2.5.1 in /usr/local/lib/python3.7/site-packages (from gutenberg) (2.22.0)\n",
      "Requirement already satisfied: rdflib-sqlalchemy>=0.3.8 in /usr/local/lib/python3.7/site-packages (from gutenberg) (0.3.8)\n",
      "Requirement already satisfied: rdflib>=4.2.0 in /usr/local/lib/python3.7/site-packages (from gutenberg) (4.2.2)\n",
      "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/site-packages (from gutenberg) (0.17.1)\n",
      "Requirement already satisfied: SPARQLWrapper>=1.8.2 in /usr/local/lib/python3.7/site-packages (from gutenberg) (1.8.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (1.25.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (2.8)\n",
      "Requirement already satisfied: SQLAlchemy>=1.1.4 in /usr/local/lib/python3.7/site-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.3.7)\n",
      "Requirement already satisfied: alembic>=0.8.8 in /usr/local/lib/python3.7/site-packages (from rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/site-packages (from rdflib>=4.2.0->gutenberg) (2.4.0)\n",
      "Requirement already satisfied: isodate in /usr/local/lib/python3.7/site-packages (from rdflib>=4.2.0->gutenberg) (0.6.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.7/site-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.0)\n",
      "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/site-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.0.4)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/site-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/site-packages (from Mako->alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!brew install berkeley-db4\n",
    "!brew install zlib\n",
    "!pip3 install gutenberg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the required packages, we can play a bit with the Gutenberg corpora and take a look at some core concepts related to NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to NLP and Core Linguistic Concepts\n",
    "\n",
    "## Ambiguity\n",
    "\n",
    "Firstly, let's cover the topic of ambiguity, and in this case, the specifics of *syntactic and lexical ambiguity*. **Ambiguity** can be referred to as the ability of having more than one meaning or being understood in more than one way. Natural languages are ambiguous, so computers are not able to understand language the way people do. Natural Language Processing (NLP) is concerned with the development of computational models of aspects of human language processing. \n",
    "\n",
    "Ambiguity can occur at various levels of NLP. Ambiguity could be **Lexical** (word-level), **Syntactic** (dealing with order of words), **Semantic** (dealing with meaning of words), **Pragmatic** (dealing with contextual meanings) etc. \n",
    "\n",
    "Lexicon and lexical simply refers to words or word-type. Syntax (other forms: syntactic) refers to the literal order of words and what can be derived from the order of these words. Semantics is dealing simply with the meaning of words without context, while pragmatics deals with meaning related to **context** and the derivation of meaning from context.\n",
    "\n",
    "The terms and definitions we use in this introductory section are interwoven with linguistics basics. The relevant and important terms that will be repeated and referenced throughout this chapter are bolded. The italicized words and phrases are important, but not absolutely necessary to understand the rest of the content in this book.\n",
    "\n",
    "Let's take a quick look at an example of *lexical ambiguity*. We are loading a **corpus** (plural: corpora/corpuses), or a body of text(s), from Project Gutenberg, and using the text to extract the context of a certain word we're looking up in the corpus. \n",
    "\n",
    "This function, `give_me_context`, is defined here to allow us to quickly and easily see the context for any given word given a corpus and the context window (the number of words on each side of the word) that we would like to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus name: \n",
      "MOBY-DICK;\n",
      "\n",
      "or, THE WHALE.\n",
      "\n",
      "By Herman Melville\n",
      "\n",
      "Length of the loaded corpus: 194853 words\n"
     ]
    }
   ],
   "source": [
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "from pprint import pprint\n",
    "\n",
    "text = strip_headers(load_etext(2701)).strip()\n",
    "print(\"Corpus name: \\n{0}\\n\".format(text[0:46]))\n",
    "\n",
    "print(\"Length of the loaded corpus: {0} words\".format(len(text.split(\" \"))))\n",
    "\n",
    "def give_me_context(text, word, context_window):\n",
    "    text = text.casefold()\n",
    "    space = \" \"\n",
    "    count = 1\n",
    "    li = []\n",
    "    \n",
    "    for word_counter, i in enumerate(text.split()):\n",
    "        if i.casefold() == word.casefold():\n",
    "            li.append(\"{0}. {1}\\n\".format(str(count),\n",
    "                                                      space.join(\n",
    "                                                          text.split()[word_counter-context_window:\n",
    "                                                                       word_counter+context_window])))\n",
    "            count+=1\n",
    "                     \n",
    "    if count==1:\n",
    "        print(\"Couldn't find \\\"{0}\\\" in the corpus.\".format(word.lower()))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the length of the corpus is quite large. We're going to be using Moby-dick by Herman Melville to demonstrate some of the aforementioned ambiguities. \n",
    "\n",
    "Let's use the word \"learned\" in this example. Learned can either be the past tense of learn, or it can simply mean knowledgable. Let's see if we can decipher the two meanings given context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. —_Sir William Davenant. Preface to Gondibert_. “What spermacetti is, men '\n",
      " 'might justly doubt, since the learned Hosmannus in his work of thirty years, '\n",
      " 'saith plainly, _Nescio quid sit_.” —_Sir T.\\n',\n",
      " '2. Tarshish could have been no other city than the modern Cadiz. That’s the '\n",
      " 'opinion of learned men. And where is Cadiz, shipmates? Cadiz is in Spain; as '\n",
      " 'far by water,\\n',\n",
      " '3. take sich dangerous weepons in their rooms at night. So, Mr. Queequeg” '\n",
      " '(for she had learned his name), “I will just take this here iron, and keep '\n",
      " 'it for you\\n',\n",
      " '4. say, that though the Captain is very discreet and scientific here, yet, '\n",
      " 'for all his learned “binnacle deviations,” “azimuth compass observations,” '\n",
      " 'and “approximate errors,” he knows very well, Captain Sleet,\\n',\n",
      " '5. Though, upon the whole, I greatly admire and even love the brave, the '\n",
      " 'honest, and learned Captain; yet I take it very ill of him that he should so '\n",
      " 'utterly\\n',\n",
      " '6. mystical, sympathetical feeling was in me; Ahab’s quenchless feud seemed '\n",
      " 'mine. With greedy ears I learned the history of that murderous monster '\n",
      " 'against whom I and all the others had\\n',\n",
      " '7. this glorious thing is utterly unknown to men ashore! never! But some '\n",
      " 'time after, I learned that goney was some seaman’s name for albatross. So '\n",
      " 'that by no possibility could\\n']\n"
     ]
    }
   ],
   "source": [
    "l = give_me_context(text, \"learned\", 15)\n",
    "pprint(l[0:7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can clearly see the difference between these two words in example 5 and example 6. In example 5, the word \"learned\" describes Captain, referring to a knowledgeable Captain. In example 6, it refers to the narrator learning of the history of the \"murderous monster,\" meaning it uses the past tense verb form of the word \"learn.\" This is a clear example of lexical, or word-level, ambiguity. These two words are considered *homographs* or words that are spelled the same but have different meanings. This basically means, on a word by word basis, just looking at the single word without context, we cannot decipher the word **sense**, or meaning, of the given word. \n",
    "\n",
    "There are also other types of ambiguity as we have mentioned above, like syntactic ambiguity. This refers to the presence of two or more possible meanings within a single sentence or sequence of words; this can also be referred to as structural or grammatical ambiguity. A quick example from our corpus is demonstrated below with the word \"mole\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. where that noble mole is washed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l = give_me_context(text, \"mole\", 3)\n",
    "print(l[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first occurrence of the word \"mole,\" in Moby Dick, we see that with limited context, the phrase \"where that noble mole is washed\" seems quite strange, and could be referring to a number of different things. \n",
    "\n",
    "Firstly, it could actually mean where an aristocratic mole, the animal, is bathed and washed, which in and of itself is quite strange (yet pleasing to think about). Or it could be referring to, as I know from previous knowledge reading the book, the city in which this entire narrative takes place, using a metaphor to refer to the city's downtown area that's been battered and shaped by the sea. Without further context, we cannot confirm or deny either of these suspicions. This is what we refer to as *syntactic ambiguity*.\n",
    "\n",
    "The meaning of the sentence depends on an understanding of the context and the speaker's intent. As defined in linguistics, a sentence is an abstract entity—-a string of words divorced from non-linguistic context--in contrast to an **utterance**, which is a concrete example of a speech act in a specific context. The more closely conscious subjects stick to common words, idioms, phrasings, and topics, the more easily others can surmise their meaning; simultaneously, the further they stray from common expressions and topics, the wider the variations in interpretations.\n",
    "\n",
    "Even with some context, there's ambiguity as to the meaning of the phrase/sentence.\n",
    "\n",
    "Let's look further at the rest of the sentence regarding the \"mole\" for context and clarify what the meaning here of \"mole\" from the text actually is, and if our wish of having a royal mole being bathed will be satisfied by the classical text of Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1. Its extreme downtown is the battery, where that noble mole is washed by '\n",
      " 'waves, and cooled by breezes,\\n')\n"
     ]
    }
   ],
   "source": [
    "l = give_me_context(text, \"mole\", 9)\n",
    "pprint(l[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we are presented with further context, the meaning becomes clearer. Sometimes context can resolve ambiguity, but the more limited the context window, like our first window of 3, the harder it becomes to derive meaning and resolve the issue of ambiguity.\n",
    "\n",
    "But there are other times where not even context can help. In those situations, you have to have a previous knowledge base or understanding of the situation for you, or the machine, to understand the different meanings a sentence, word, or phrase. This is one of the largest problems for NLP; the existence of a lack of clear understanding of phrases and sentences without prior, previous, or contextual knowledge.\n",
    "\n",
    "This also suggests that sentences do not have an intrinsic meaning, that there is no meaning associated with a sentence or word, and that either only represent an idea symbolically. \"The dog sat on the carpet\" is a sentence in English. If someone were to say to someone else, \"The dog sat on the carpet,\" the act is itself an utterance. This implies that a sentence, term, expression or word cannot symbolically represent a single true meaning; such meaning is underspecified (which dog sat on which carpet?) and consequently, is potentially ambiguous. By contrast, the meaning of an utterance can be inferred through knowledge of its context, or **pragmatics**, leveraging both its linguistic and non-linguistic contexts (which may or may not be sufficient to resolve ambiguity). You may factually know from previous conversations it's your neighbour's dog, or the carpet referred to is the Persian carpet you keep in your bedroom, or even that the dog didn't actually sit normally, because the neighbour's dog has a hip problem and causes him to lay more than sit, yet the closest word to describe what the dog did is to use sit. All of these are ambiguous from the sentence \"The dog sat on the carpet,\" and having a limited context can allow the sentence to become more and more ambiguous and answer less and less questions.\n",
    "\n",
    "It's almost like having a vector in which an element is 3, but that 3 could sometimes be 4, 5, 6, 7, and sometimes 14, but you don't necessarily have the information to make that determination. This lack of knowledge, and the lack of determination makes ambiguity such a large issue in NLP and fundamentally a harder problem than some other parts of Deep Learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compositionality\n",
    "\n",
    "Compositionality is the other beast that presents itself as a basic roadblock in the field of NLP. It is highly related to ambiguity and the previous section. \n",
    "\n",
    "The requirements for a language to be **compositional** are the following:\n",
    "    - The meaning of the sentence doesn't directly depend on\n",
    "        - things said earlier in the conversation\n",
    "        - the beliefs or intentions of the person uttering the sentence\n",
    "        - objects that are salient or events in the environment when the sentence is spoken/written\n",
    "        - the non-semantic character of the sentences simple parts like their shape or sound\n",
    "\n",
    "Clearly this is almost impossible for any sort of natural language; languages like Python, though, are strictly compositional, if we consider lines of code to be sentences. But no natural language has this; the presence of puns, conversation topics about things in or around a room, references to older conversations or in-jokes, or even the belief and intention of the person saying the sentence, are all regular participants in a conversation or piece of text. So why is this such a big deal?\n",
    "\n",
    "This issue rears its head as machines and some of the current models rely heavily on a language being compositional to be effective. For a model to derive meaning, the only access it has is to the words in the text it's been given, or a previous knowledge base it's been given. When looking at a small portion of text, the better the knowledge base, the better the understanding the model will have of the text. But in most situations, this knowledge graph and knowledge base is hard to construct or entirely lacking. Instead, a model largely has to depend on context and semantic relationships to derive meaning for words. Basically, the principle, also known as Frege's principle or the principle of compositionality, is the theory that \"the meaning of a \\[sentence or utterance\\] is determined by the meanings of its constituent expressions and the rules used to combine them.\" Many NLP algorithms rely heavily on this principle and derive the \"meaning\" or their representations based upon the prior statement. \n",
    "\n",
    "Let's look at a sentence from the first passage of the second chapter of Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1. I stuffed a shirt or two into my old carpet-bag, tucked it under my arm, '\n",
      " 'and started for Cape Horn\\n')\n"
     ]
    }
   ],
   "source": [
    "l = give_me_context(text, \"tucked\", 10)\n",
    "pprint(l[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entirety of the sentence's meaning is only based on the meaning of the constituents. There is no ambiguity, the language here is entirely compositional, specifically referring to the narrator putting one or two shirts in his bag and starting his journey to Cape Horn. There are some cases in which natural languages are strictly compositional. But then, take for example, the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Poor Lazarus there, chattering his teeth against the curbstone for his '\n",
      " 'pillow, and shaking off his tatters with his shiverings, he might plug up '\n",
      " 'both ears with rags, and put a corn-cob into his mouth, and yet that would '\n",
      " 'not keep out the tempestuous Euroclydon. Euroclydon! says old\\n')\n"
     ]
    }
   ],
   "source": [
    "l = give_me_context(text, \"curbstone\", 40)\n",
    "pprint(l[0][177:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sentence here references Lazarus, the disciple and miracle of Jesus Christ, and Euroclydon, a tempestuous northeast wind which blew in the Mediterranean in certain seasons. Without prior knowledge or a knowledge base, an algorithm would not have possibly known of these two terms, or been able to understand from context the meaning of this sentence. The principle of compositionality here, fails for the English language. \n",
    "\n",
    "And this is exactly why NLP is such a difficult sub-field of deep learning: the presence of ambiguity and the failing of compositionality in metaphorical and referential natural language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The natural next question then, is how do we attempt to create numeric representations of words, sentences, and documents on which we can train models keeping these two issues in mind? \n",
    "\n",
    "We start answering exactly that on a word level in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
